# ðŸŒŸ Multi-AI Provider Environment Configuration

# Copy this to your .env file in the .windsurf/server directory

# ==================== EXISTING CONFIGURATION ====================

# PostgreSQL Configuration
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_USER=ventai_enterprise
POSTGRES_PASSWORD=your_secure_password
POSTGRES_DB=ventai_enterprise

# Redis Configuration  
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=your_redis_password

# Vector Store Configuration
VECTOR_DIMENSIONS=1536
ENABLE_VECTOR_STORE=true

# ==================== NEW AI PROVIDERS CONFIGURATION ====================

# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here
# Optional: specify default model
OPENAI_DEFAULT_MODEL=gpt-4o
OPENAI_EMBEDDING_MODEL=text-embedding-ada-002

# Anthropic Claude Configuration  
ANTHROPIC_API_KEY=your_anthropic_api_key_here
# Optional: specify default model
ANTHROPIC_DEFAULT_MODEL=claude-3-5-sonnet-20241022

# Google Gemini Configuration
GEMINI_API_KEY=your_gemini_api_key_here
# Optional: specify default model
GEMINI_DEFAULT_MODEL=gemini-1.5-pro
GEMINI_EMBEDDING_MODEL=text-embedding-004

# Mistral AI Configuration
MISTRAL_API_KEY=your_mistral_api_key_here
# Optional: specify default model
MISTRAL_DEFAULT_MODEL=mistral-large-latest
MISTRAL_EMBEDDING_MODEL=mistral-embed

# Grok (X.AI) Configuration  
GROK_API_KEY=your_grok_api_key_here
# Optional: specify default model
GROK_DEFAULT_MODEL=grok-beta

# Local Ollama Configuration (Optional)
# Uncomment and configure if you want to use local models
# OLLAMA_BASE_URL=http://localhost:11434
# OLLAMA_DEFAULT_MODEL=llama3:latest
# OLLAMA_EMBEDDING_MODEL=nomic-embed-text:latest

# ==================== AI PROVIDER SETTINGS ====================

# Enable/disable specific providers
ENABLE_OPENAI=true
ENABLE_ANTHROPIC=true  
ENABLE_GEMINI=true
ENABLE_MISTRAL=true
ENABLE_GROK=false
ENABLE_OLLAMA=false
ENABLE_WINDSURF=true

# Provider priority for chat (comma-separated)
AI_CHAT_PRIORITY=anthropic,openai,google,windsurf,local,mistral,grok

# Provider priority for embeddings (comma-separated)  
AI_EMBEDDING_PRIORITY=openai,google,mistral,local

# Request timeout in milliseconds
AI_REQUEST_TIMEOUT=30000

# Max retries for failed requests
AI_MAX_RETRIES=3

# Enable automatic fallback
AI_ENABLE_FALLBACK=true

# ==================== LOGGING & MONITORING ====================

# AI operation logging
LOG_AI_REQUESTS=true
LOG_AI_RESPONSES=false
LOG_AI_ERRORS=true

# Performance monitoring
TRACK_AI_PERFORMANCE=true
TRACK_TOKEN_USAGE=true

# ==================== DEVELOPMENT/TESTING ====================

# Test API keys (for development only)
# Uncomment these lines for testing without real API keys
# OPENAI_API_KEY=test-openai-key-12345
# ANTHROPIC_API_KEY=test-anthropic-key-12345
# GEMINI_API_KEY=test-gemini-key-12345
# MISTRAL_API_KEY=test-mistral-key-12345

# Enable AI testing mode (uses mock responses)
AI_TESTING_MODE=false

# ==================== SECURITY ====================

# Rate limiting
AI_RATE_LIMIT_REQUESTS_PER_MINUTE=60
AI_RATE_LIMIT_TOKENS_PER_MINUTE=100000

# API key encryption (set to true in production)
ENCRYPT_API_KEYS=false
API_KEY_ENCRYPTION_SECRET=your_encryption_secret_32_chars

# ==================== WINDSURF INTEGRATION ====================

# Windsurf project context
WINDSURF_PROJECT_ROOT=/Users/olegkizyma/workspaces/MVP/ventai-app
WINDSURF_CONTEXT_DEPTH=5
WINDSURF_INCLUDE_GITIGNORE=true

# File patterns to include in Windsurf context
WINDSURF_INCLUDE_PATTERNS=**/*.ts,**/*.tsx,**/*.js,**/*.jsx,**/*.py,**/*.md
WINDSURF_EXCLUDE_PATTERNS=node_modules/**,dist/**,build/**,coverage/**

# ==================== EXAMPLE VALUES ====================
# Replace these with your actual API keys

# Example OpenAI key format: sk-proj-1234567890abcdef...
# Example Anthropic key format: sk-ant-api03-1234567890abcdef...  
# Example Gemini key format: AIzaSy1234567890abcdef...
# Example Mistral key format: 1234567890abcdef...
# Example Grok key format: xai-1234567890abcdef...
