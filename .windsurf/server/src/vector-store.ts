#!/usr/bin/env node

import { config } from 'dotenv';
import { createClient } from 'redis';

// –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –∑–º—ñ–Ω–Ω—ñ —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞
config({ path: './.env' });
import { Pool } from 'pg';
import fs from 'fs-extra';
import { promises as fsPromises } from 'fs';
import { createTwoFilesPatch } from 'diff';
import { minimatch } from 'minimatch';
import { MultiAIProvider } from './multi-ai-provider.js';

/**
 * üéØ Enterprise Vector Store –¥–ª—è Windsurf MCP System
 * –Ü–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—è PostgreSQL + Redis + Vector DB –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤/–∑–∞–≤–¥–∞–Ω—å
 */

interface VectorDocument {
  id: string;
  type: 'changelog' | 'phase' | 'task' | 'file' | 'rule' | 'activation';
  content: string;
  metadata: {
    phase?: string;
    timestamp: string;
    path: string;
    status?: string;
    priority?: number;
    tags?: string[];
    operation?: string;
    editsSummary?: string;
    [key: string]: any;
  };
  embedding?: number[];
  graph_connections?: string[];
}

interface GraphNode {
  id: string;
  type: string;
  properties: Record<string, any>;
  relationships: Array<{
    target: string;
    type: 'DEPENDS_ON' | 'PART_OF' | 'TRIGGERS' | 'REFERENCES';
    weight?: number;
  }>;
}

export class WindsurfVectorStore {
  private redis: any;
  private postgres: Pool;
  private aiProvider: MultiAIProvider;
  private vectorDimension = 1536; // OpenAI ada-002 dimensions

  constructor() {
    // Redis connection –¥–ª—è –∫–µ—à—É–≤–∞–Ω–Ω—è —Ç–∞ —à–≤–∏–¥–∫–æ–≥–æ –¥–æ—Å—Ç—É–ø—É
    this.redis = createClient({
      url: process.env.REDIS_URL || 'redis://localhost:6380'
    });

    // PostgreSQL –∑ pgvector –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–∏—Ö –æ–ø–µ—Ä–∞—Ü—ñ–π
    this.postgres = new Pool({
      connectionString: process.env.DATABASE_URL || 'postgresql://ventai_dev:ventai_dev_password@localhost:5433/ventai_dev',
      max: 20,
      idleTimeoutMillis: 30000,
      connectionTimeoutMillis: 2000,
    });

    // Multi-AI Provider –¥–ª—è —Ä–æ–±–æ—Ç–∏ –∑ —Ä—ñ–∑–Ω–∏–º–∏ AI –º–æ–¥–µ–ª—è–º–∏
    this.aiProvider = new MultiAIProvider();

    this.initializeDatabase();
  }

  /**
   * üîß –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –≤–µ–∫—Ç–æ—Ä–Ω–æ—ó –±–∞–∑–∏ –¥–∞–Ω–∏—Ö
   */
  private async initializeDatabase(): Promise<void> {
    try {
      await this.redis.connect();
      console.log('‚úÖ Redis connected for Windsurf Vector Store');

      // –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Ç–∞–±–ª–∏—Ü—å –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è
      await this.postgres.query(`
        CREATE EXTENSION IF NOT EXISTS vector;
        
        -- –¢–∞–±–ª–∏—Ü—è –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤
        CREATE TABLE IF NOT EXISTS windsurf_documents (
          id VARCHAR(255) PRIMARY KEY,
          type VARCHAR(50) NOT NULL,
          content TEXT NOT NULL,
          metadata JSONB DEFAULT '{}',
          embedding vector(${this.vectorDimension}),
          created_at TIMESTAMP DEFAULT NOW(),
          updated_at TIMESTAMP DEFAULT NOW(),
          search_vector tsvector GENERATED ALWAYS AS (to_tsvector('english', content)) STORED
        );

        -- –¢–∞–±–ª–∏—Ü—è –¥–ª—è –≥—Ä–∞—Ñ–æ–≤–∏—Ö –∑–≤'—è–∑–∫—ñ–≤
        CREATE TABLE IF NOT EXISTS windsurf_graph (
          id VARCHAR(255) PRIMARY KEY,
          source_id VARCHAR(255) REFERENCES windsurf_documents(id),
          target_id VARCHAR(255) REFERENCES windsurf_documents(id),
          relationship_type VARCHAR(50) NOT NULL,
          weight FLOAT DEFAULT 1.0,
          metadata JSONB DEFAULT '{}',
          created_at TIMESTAMP DEFAULT NOW()
        );

        -- –Ü–Ω–¥–µ–∫—Å–∏ –¥–ª—è –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó
        CREATE INDEX IF NOT EXISTS idx_windsurf_docs_type ON windsurf_documents(type);
        CREATE INDEX IF NOT EXISTS idx_windsurf_docs_metadata ON windsurf_documents USING GIN(metadata);
        CREATE INDEX IF NOT EXISTS idx_windsurf_docs_search ON windsurf_documents USING GIN(search_vector);
        CREATE INDEX IF NOT EXISTS idx_windsurf_docs_embedding ON windsurf_documents USING ivfflat (embedding vector_cosine_ops);
        CREATE INDEX IF NOT EXISTS idx_windsurf_graph_source ON windsurf_graph(source_id);
        CREATE INDEX IF NOT EXISTS idx_windsurf_graph_target ON windsurf_graph(target_id);
        CREATE INDEX IF NOT EXISTS idx_windsurf_graph_type ON windsurf_graph(relationship_type);
      `);

      console.log('‚úÖ PostgreSQL Vector Store initialized');
    } catch (error) {
      console.error('‚ùå Vector Store initialization failed:', error);
    }
  }

  /**
   * üìÑ –î–æ–¥–∞–≤–∞–Ω–Ω—è –¥–æ–∫—É–º–µ–Ω—Ç—É –¥–æ –≤–µ–∫—Ç–æ—Ä–Ω–æ—ó –±–∞–∑–∏ –∑ –ø—ñ–¥—Ç—Ä–∏–º–∫–æ—é –≤–µ–ª–∏–∫–∏—Ö —Ñ–∞–π–ª—ñ–≤
   */
  async addDocument(doc: VectorDocument): Promise<void> {
    try {
      // –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Ä–æ–∑–º—ñ—Ä—É –∫–æ–Ω—Ç–µ–Ω—Ç—É (PostgreSQL tsvector –ª—ñ–º—ñ—Ç: 1MB)
      const contentSize = Buffer.byteLength(doc.content, 'utf8');
      
      if (contentSize > 800000) { // 800KB safety margin
        console.log(`üìÑ Large document detected (${Math.round(contentSize/1024)}KB), splitting...`);
        
        // –†–æ–∑–±–∏–≤–∞—î–º–æ –≤–µ–ª–∏–∫–∏–π –¥–æ–∫—É–º–µ–Ω—Ç –Ω–∞ —á–∞—Å—Ç–∏–Ω–∏
        const chunks = this.splitLargeDocument(doc.content);
        
        for (let i = 0; i < chunks.length; i++) {
          const chunkDoc: VectorDocument = {
            ...doc,
            id: `${doc.id}_chunk_${i + 1}`,
            content: chunks[i],
            metadata: {
              ...doc.metadata,
              isChunk: true,
              chunkNumber: i + 1,
              totalChunks: chunks.length,
              originalDocId: doc.id
            }
          };
          
          await this.addSingleDocument(chunkDoc);
        }
        
        console.log(`‚úÖ Split large document into ${chunks.length} chunks`);
        return;
      }
      
      // –ó–≤–∏—á–∞–π–Ω–∞ –æ–±—Ä–æ–±–∫–∞ –¥–ª—è –Ω–µ–≤–µ–ª–∏–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤
      await this.addSingleDocument(doc);
      
    } catch (error) {
      console.error(`‚ùå Failed to add document ${doc.id}:`, error);
      throw error;
    }
  }

  /**
   * üìù –î–æ–¥–∞–≤–∞–Ω–Ω—è –æ–¥–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç—É (–≤–Ω—É—Ç—Ä—ñ—à–Ω—è —Ñ—É–Ω–∫—Ü—ñ—è)
   */
  private async addSingleDocument(doc: VectorDocument): Promise<void> {
    try {
      // –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è embedding –∑ Multi-AI Provider
      let embedding: number[] | null = null;
      if (doc.content.length > 10) {
        try {
          const embeddingResult = await this.aiProvider.createEmbeddings(
            doc.content.substring(0, 8000) // –õ—ñ–º—ñ—Ç –¥–ª—è –±—ñ–ª—å—à–æ—Å—Ç—ñ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ñ–≤
          );
          embedding = embeddingResult.embedding;
          console.log(`‚úÖ Embedding created using ${embeddingResult.provider} (${embeddingResult.model})`);
        } catch (embeddingError) {
          console.warn('‚ö†Ô∏è Embedding generation failed, storing without vector');
        }
      }

      // –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≤ PostgreSQL
      await this.postgres.query(`
        INSERT INTO windsurf_documents (id, type, content, metadata, embedding)
        VALUES ($1, $2, $3, $4, $5)
        ON CONFLICT (id) DO UPDATE SET
          content = EXCLUDED.content,
          metadata = EXCLUDED.metadata,
          embedding = EXCLUDED.embedding,
          updated_at = NOW()
      `, [doc.id, doc.type, doc.content, JSON.stringify(doc.metadata), embedding]);

      // –ö–µ—à—É–≤–∞–Ω–Ω—è –≤ Redis –¥–ª—è —à–≤–∏–¥–∫–æ–≥–æ –¥–æ—Å—Ç—É–ø—É
      await this.redis.setEx(
        `windsurf:doc:${doc.id}`,
        3600, // 1 –≥–æ–¥–∏–Ω–∞
        JSON.stringify(doc)
      );

      // –Ü–Ω–¥–µ–∫—Å–∞—Ü—ñ—è –¥–ª—è –ø–æ—à—É–∫—É
      await this.redis.sAdd(`windsurf:type:${doc.type}`, doc.id);

      // –î–æ–¥–∞–≤–∞–Ω–Ω—è —Ç–µ–≥—ñ–≤ –¥–æ —ñ–Ω–¥–µ–∫—Å—É
      if (doc.metadata.tags) {
        for (const tag of doc.metadata.tags) {
          await this.redis.sAdd(`windsurf:tag:${tag}`, doc.id);
        }
      }

      console.log(`‚úÖ Document added to vector store: ${doc.id}`);
    } catch (error) {
      console.error(`‚ùå Failed to add document ${doc.id}:`, error);
      throw error;
    }
  }

  /**
   * üîç –í–µ–∫—Ç–æ—Ä–Ω–∏–π –ø–æ—à—É–∫ –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤
   */
  async vectorSearch(query: string, limit: number = 10, type?: string): Promise<VectorDocument[]> {
    try {
      // –°–ø—Ä–æ–±—É—î–º–æ –≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ embedding –¥–ª—è –ø–æ—à—É–∫—É
      let queryEmbedding: number[];
      try {
        const embeddingResult = await this.aiProvider.createEmbeddings(query);
        queryEmbedding = embeddingResult.embedding;
        console.log(`üîç Search embedding created using ${embeddingResult.provider}`);
      } catch (error) {
        console.log('üîÑ Embedding unavailable, using text search fallback');
        return this.textSearch(query, limit, type);
      }

      // –í–µ–∫—Ç–æ—Ä–Ω–∏–π –ø–æ—à—É–∫ –≤ PostgreSQL
      let sql = `
        SELECT id, type, content, metadata, embedding <=> $1 AS distance
        FROM windsurf_documents
        WHERE embedding IS NOT NULL
      `;
      const params: any[] = [JSON.stringify(queryEmbedding)];

      if (type) {
        sql += ` AND type = $2`;
        params.push(type);
      }

      sql += ` ORDER BY distance LIMIT $${params.length + 1}`;
      params.push(limit);

      const result = await this.postgres.query(sql, params);

      return result.rows.map(row => ({
        id: row.id,
        type: row.type,
        content: row.content,
        metadata: row.metadata,
        embedding: row.embedding
      }));
    } catch (error) {
      console.error('‚ùå Vector search failed:', error);
      return this.textSearch(query, limit, type);
    }
  }

  /**
   * üìù –¢–µ–∫—Å—Ç–æ–≤–∏–π –ø–æ—à—É–∫ (fallback)
   */
  async textSearch(query: string, limit: number = 10, type?: string): Promise<VectorDocument[]> {
    try {
      let sql = `
        SELECT id, type, content, metadata,
               ts_rank(search_vector, plainto_tsquery($1)) AS rank
        FROM windsurf_documents
        WHERE search_vector @@ plainto_tsquery($1)
      `;
      const params: any[] = [query];

      if (type) {
        sql += ` AND type = $2`;
        params.push(type);
      }

      sql += ` ORDER BY rank DESC LIMIT $${params.length + 1}`;
      params.push(limit);

      const result = await this.postgres.query(sql, params);

      return result.rows.map(row => ({
        id: row.id,
        type: row.type,
        content: row.content,
        metadata: row.metadata
      }));
    } catch (error) {
      console.error('‚ùå Text search failed:', error);
      return [];
    }
  }

  /**
   * üï∏Ô∏è –î–æ–¥–∞–≤–∞–Ω–Ω—è –≥—Ä–∞—Ñ–æ–≤–æ–≥–æ –∑–≤'—è–∑–∫—É
   */
  async addGraphRelationship(
    sourceId: string,
    targetId: string,
    relationshipType: string,
    weight: number = 1.0,
    metadata: Record<string, any> = {}
  ): Promise<void> {
    try {
      const relationshipId = `${sourceId}_${relationshipType}_${targetId}`;
      
      await this.postgres.query(`
        INSERT INTO windsurf_graph (id, source_id, target_id, relationship_type, weight, metadata)
        VALUES ($1, $2, $3, $4, $5, $6)
        ON CONFLICT (id) DO UPDATE SET
          weight = EXCLUDED.weight,
          metadata = EXCLUDED.metadata
      `, [relationshipId, sourceId, targetId, relationshipType, weight, JSON.stringify(metadata)]);

      // –ö–µ—à—É–≤–∞–Ω–Ω—è –≥—Ä–∞—Ñ—É –≤ Redis
      await this.redis.sAdd(`windsurf:graph:${sourceId}`, `${relationshipType}:${targetId}:${weight}`);

      console.log(`‚úÖ Graph relationship added: ${sourceId} -[${relationshipType}]-> ${targetId}`);
    } catch (error) {
      console.error('‚ùå Failed to add graph relationship:', error);
      throw error;
    }
  }

  /**
   * üåê –û—Ç—Ä–∏–º–∞–Ω–Ω—è –≥—Ä–∞—Ñ–æ–≤–∏—Ö –∑–≤'—è–∑–∫—ñ–≤
   */
  async getGraphConnections(nodeId: string, depth: number = 1): Promise<GraphNode[]> {
    try {
      const visited = new Set<string>();
      const nodes: GraphNode[] = [];
      const queue = [{ id: nodeId, currentDepth: 0 }];

      while (queue.length > 0) {
        const { id, currentDepth } = queue.shift()!;
        
        if (visited.has(id) || currentDepth > depth) continue;
        visited.add(id);

        // –û—Ç—Ä–∏–º–∞–Ω–Ω—è –¥–æ–∫—É–º–µ–Ω—Ç—É
        const doc = await this.getDocument(id);
        if (!doc) continue;

        // –û—Ç—Ä–∏–º–∞–Ω–Ω—è –∑–≤'—è–∑–∫—ñ–≤
        const relationships: any[] = [];
        const graphQuery = await this.postgres.query(`
          SELECT target_id, relationship_type, weight, metadata
          FROM windsurf_graph
          WHERE source_id = $1
        `, [id]);

        for (const rel of graphQuery.rows) {
          relationships.push({
            target: rel.target_id,
            type: rel.relationship_type,
            weight: rel.weight
          });

          if (currentDepth < depth) {
            queue.push({ id: rel.target_id, currentDepth: currentDepth + 1 });
          }
        }

        nodes.push({
          id,
          type: doc.type,
          properties: doc.metadata,
          relationships
        });
      }

      return nodes;
    } catch (error) {
      console.error('‚ùå Failed to get graph connections:', error);
      return [];
    }
  }

  /**
   * üìñ –û—Ç—Ä–∏–º–∞–Ω–Ω—è –¥–æ–∫—É–º–µ–Ω—Ç—É –∑–∞ ID
   */
  async getDocument(id: string): Promise<VectorDocument | null> {
    try {
      // –°–ø–æ—á–∞—Ç–∫—É –∑ –∫–µ—à—É Redis
      const cached = await this.redis.get(`windsurf:doc:${id}`);
      if (cached) {
        return JSON.parse(cached);
      }

      // –ü–æ—Ç—ñ–º –∑ PostgreSQL
      const result = await this.postgres.query(
        'SELECT * FROM windsurf_documents WHERE id = $1',
        [id]
      );

      if (result.rows.length === 0) return null;

      const doc = {
        id: result.rows[0].id,
        type: result.rows[0].type,
        content: result.rows[0].content,
        metadata: result.rows[0].metadata,
        embedding: result.rows[0].embedding
      };

      // –ö–µ—à—É–≤–∞–Ω–Ω—è –≤ Redis
      await this.redis.setEx(`windsurf:doc:${id}`, 3600, JSON.stringify(doc));

      return doc;
    } catch (error) {
      console.error(`‚ùå Failed to get document ${id}:`, error);
      return null;
    }
  }

  /**
   * üìä –ê–Ω–∞–ª—ñ—Ç–∏–∫–∞ –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö
   */
  async getAnalytics(): Promise<any> {
    try {
      const stats = await this.postgres.query(`
        SELECT 
          type,
          COUNT(*) as count,
          AVG(CASE WHEN embedding IS NOT NULL THEN 1 ELSE 0 END) as embedding_coverage
        FROM windsurf_documents
        GROUP BY type
      `);

      const graphStats = await this.postgres.query(`
        SELECT 
          relationship_type,
          COUNT(*) as count,
          AVG(weight) as avg_weight
        FROM windsurf_graph
        GROUP BY relationship_type
      `);

      return {
        documents: stats.rows,
        relationships: graphStats.rows,
        totalDocuments: stats.rows.reduce((sum, row) => sum + parseInt(row.count), 0),
        totalRelationships: graphStats.rows.reduce((sum, row) => sum + parseInt(row.count), 0)
      };
    } catch (error) {
      console.error('‚ùå Failed to get analytics:', error);
      return { documents: [], relationships: [], totalDocuments: 0, totalRelationships: 0 };
    }
  }

  /**
   * üîÑ –°–∏–Ω—Ö—Ä–æ–Ω—ñ–∑–∞—Ü—ñ—è –∑ —Ñ–∞–π–ª–æ–≤–æ—é —Å–∏—Å—Ç–µ–º–æ—é Windsurf
   */
  async syncWindsurfFiles(windsurfPath: string): Promise<void> {
    try {
      console.log('üîÑ Syncing Windsurf files to vector store...');

      // –°–∏–Ω—Ö—Ä–æ–Ω—ñ–∑–∞—Ü—ñ—è CHANGELOG.md
      const changelogPath = `${windsurfPath}/CHANGELOG.md`;
      if (await fs.pathExists(changelogPath)) {
        const content = await fsPromises.readFile(changelogPath, 'utf-8');
        await this.addDocument({
          id: 'changelog_master',
          type: 'changelog',
          content,
          metadata: {
            path: changelogPath,
            timestamp: new Date().toISOString(),
            tags: ['changelog', 'master', 'progress']
          }
        });
      }

      // –°–∏–Ω—Ö—Ä–æ–Ω—ñ–∑–∞—Ü—ñ—è docs/changelog/
      const changelogDir = `${windsurfPath}/docs/changelog`;
      if (await fs.pathExists(changelogDir)) {
        const files = await fs.readdir(changelogDir);
        for (const file of files) {
          if (file.endsWith('.md')) {
            const filePath = `${changelogDir}/${file}`;
            const content = await fsPromises.readFile(filePath, 'utf-8');
            const phaseMatch = file.match(/phase(\d+(?:\.\d+)?)/);
            
            await this.addDocument({
              id: `phase_${file.replace('.md', '')}`,
              type: 'phase',
              content,
              metadata: {
                path: filePath,
                phase: phaseMatch ? phaseMatch[1] : 'unknown',
                timestamp: new Date().toISOString(),
                tags: ['phase', 'changelog', phaseMatch ? `phase-${phaseMatch[1]}` : 'misc']
              }
            });

            // –î–æ–¥–∞–≤–∞–Ω–Ω—è –∑–≤'—è–∑–∫—É –∑ –≥–æ–ª–æ–≤–Ω–∏–º changelog
            await this.addGraphRelationship(
              'changelog_master',
              `phase_${file.replace('.md', '')}`,
              'CONTAINS',
              1.0
            );
          }
        }
      }

      // –°–∏–Ω—Ö—Ä–æ–Ω—ñ–∑–∞—Ü—ñ—è .windsurf/ –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—ó
      const windsurfConfigDir = `${windsurfPath}/.windsurf`;
      await this.syncDirectory(windsurfConfigDir, 'rule');

      console.log('‚úÖ Windsurf files synchronized to vector store');
    } catch (error) {
      console.error('‚ùå Windsurf sync failed:', error);
    }
  }

  /**
   * üìÅ –°–∏–Ω—Ö—Ä–æ–Ω—ñ–∑–∞—Ü—ñ—è –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—ó
   */
  private async syncDirectory(dirPath: string, type: string): Promise<void> {
    if (!await fs.pathExists(dirPath)) return;

    const items = await fs.readdir(dirPath, { withFileTypes: true });
    
    for (const item of items) {
      const itemPath = `${dirPath}/${item.name}`;
      
      if (item.isFile() && item.name.endsWith('.md')) {
        const content = await fsPromises.readFile(itemPath, 'utf-8');
        const docId = `${type}_${item.name.replace('.md', '')}`;
        
        await this.addDocument({
          id: docId,
          type: type as any,
          content,
          metadata: {
            path: itemPath,
            timestamp: new Date().toISOString(),
            tags: [type, item.name.replace('.md', '')]
          }
        });
      } else if (item.isDirectory()) {
        await this.syncDirectory(itemPath, `${type}_${item.name}`);
      }
    }
  }

  /**
   * üß† –Ü–Ω—Ç–µ–ª–µ–∫—Ç—É–∞–ª—å–Ω—ñ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó
   */
  async getRecommendations(context: string, limit: number = 5): Promise<VectorDocument[]> {
    try {
      // –ü–æ—à—É–∫ —Å—Ö–æ–∂–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤
      const similar = await this.vectorSearch(context, limit * 2);
      
      // –ê–Ω–∞–ª—ñ–∑ –≥—Ä–∞—Ñ–æ–≤–∏—Ö –∑–≤'—è–∑–∫—ñ–≤
      const recommendations: VectorDocument[] = [];
      const seen = new Set<string>();

      for (const doc of similar) {
        if (recommendations.length >= limit) break;
        
        if (!seen.has(doc.id)) {
          recommendations.push(doc);
          seen.add(doc.id);
        }

        // –î–æ–¥–∞–≤–∞–Ω–Ω—è –ø–æ–≤'—è–∑–∞–Ω–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤
        const connections = await this.getGraphConnections(doc.id, 1);
        for (const conn of connections) {
          if (recommendations.length >= limit) break;
          
          for (const rel of conn.relationships) {
            if (!seen.has(rel.target)) {
              const relatedDoc = await this.getDocument(rel.target);
              if (relatedDoc) {
                recommendations.push(relatedDoc);
                seen.add(rel.target);
              }
            }
          }
        }
      }

      return recommendations.slice(0, limit);
    } catch (error) {
      console.error('‚ùå Failed to get recommendations:', error);
      return [];
    }
  }

  /**
   * üîí –ó–∞–∫—Ä–∏—Ç—Ç—è –∑'—î–¥–Ω–∞–Ω—å
   */
  async close(): Promise<void> {
    try {
      await this.redis.quit();
      await this.postgres.end();
      console.log('‚úÖ Vector Store connections closed');
    } catch (error) {
      console.error('‚ùå Failed to close connections:', error);
    }
  }

  /**
   * üìÑ –†–æ–∑–±–∏—Ç—Ç—è –≤–µ–ª–∏–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤ –Ω–∞ —á–∞—Å—Ç–∏–Ω–∏ –¥–ª—è —É–Ω–∏–∫–Ω–µ–Ω–Ω—è tsvector –ª—ñ–º—ñ—Ç—É
   */
  private splitLargeDocument(content: string, maxChunkSize: number = 800000): string[] {
    const chunks: string[] = [];
    const lines = content.split('\n');
    let currentChunk = '';
    
    for (const line of lines) {
      // –Ø–∫—â–æ –¥–æ–¥–∞–Ω–Ω—è –ª—ñ–Ω—ñ—ó –ø–µ—Ä–µ–≤–∏—â–∏—Ç—å –ª—ñ–º—ñ—Ç, –∑–±–µ—Ä—ñ–≥–∞—î–º–æ –ø–æ—Ç–æ—á–Ω–∏–π chunk
      if (currentChunk.length + line.length + 1 > maxChunkSize) {
        if (currentChunk.trim()) {
          chunks.push(currentChunk.trim());
        }
        currentChunk = line;
      } else {
        currentChunk += (currentChunk ? '\n' : '') + line;
      }
    }
    
    // –î–æ–¥–∞—î–º–æ –æ—Å—Ç–∞–Ω–Ω—ñ–π chunk
    if (currentChunk.trim()) {
      chunks.push(currentChunk.trim());
    }
    
    return chunks;
  }
}

// –ï–∫—Å–ø–æ—Ä—Ç –¥–ª—è –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –≤ MCP —Å–µ—Ä–≤–µ—Ä—ñ
export { VectorDocument, GraphNode };
